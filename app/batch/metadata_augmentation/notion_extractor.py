"""
Notion API ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (ë²”ìš©)

Notion ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ í˜ì´ì§€ ì½˜í…ì¸ ë¥¼ ì¡°íšŒí•˜ê³ 
LLMì„ í†µí•´ êµ¬ì¡°í™”ëœ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

íŠ¹ì§•:
- ì„¤ì • íŒŒì¼(domain.yaml) ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ì™€ DB IDë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œ
- ë²”ìš© ìŠ¤í‚¤ë§ˆ(GenericMetadataSchema) ì‚¬ìš©ìœ¼ë¡œ ë„ë©”ì¸ ì˜ì¡´ì„± ì œê±°
- í”„ë¡¬í”„íŠ¸ íŒŒì¼(extraction_prompts.json)ì„ í†µí•œ ì™¸ë¶€ í”„ë¡¬í”„íŠ¸ ì£¼ì…
"""

import asyncio
import json
import os
import re
from dataclasses import dataclass, field
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

from openai import AsyncOpenAI
from pydantic import ValidationError

from app.batch.metadata_augmentation.metadata_schemas.generic import GenericMetadataSchema
from app.batch.notion_client import NotionAPIClient, NotionPage
from app.lib.config_loader import load_config
from app.lib.logger import get_logger

logger = get_logger(__name__)


# =============================================================================
# ë°ì´í„° í´ë˜ìŠ¤
# =============================================================================


@dataclass
class ExtractionResult:
    """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê²°ê³¼"""

    entity_name: str
    category: str
    page_id: str
    extraction_rate: float
    filled_fields: int
    total_fields: int
    metadata: dict[str, Any]
    raw_content: str = ""
    error: str | None = None
    extracted_at: str = field(default_factory=lambda: datetime.now(UTC).isoformat())


@dataclass
class BatchResult:
    """ë°°ì¹˜ ì¶”ì¶œ ê²°ê³¼"""

    category: str
    total_pages: int
    success_count: int
    failed_count: int
    average_extraction_rate: float
    results: list[ExtractionResult]
    duration_seconds: float


# =============================================================================
# ë©”ì¸ ì¶”ì¶œê¸° í´ë˜ìŠ¤
# =============================================================================


class NotionMetadataExtractor:
    """
    Notion API ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (ë²”ìš©)
    """

    def __init__(
        self,
        notion_api_key: str | None = None,
        openrouter_api_key: str | None = None,
        output_dir: str = "data/metadata",
        model: str = "anthropic/claude-sonnet-4",
    ):
        """
        ì¶”ì¶œê¸° ì´ˆê¸°í™”

        Args:
            notion_api_key: Notion API í‚¤
            openrouter_api_key: OpenRouter API í‚¤
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
        """
        # ì„¤ì • ë¡œë“œ (ê²€ì¦ ì—†ì´ ë¡œë“œí•˜ì—¬ ìœ ì—°ì„± í™•ë³´)
        self.config = load_config(validate=False)
        domain_config = self.config.get("domain", {})
        batch_config = domain_config.get("batch", {})
        metadata_config = domain_config.get("metadata", {}).get("schema", {})

        # ì¹´í…Œê³ ë¦¬ ì„¤ì • ë§¤í•‘ (ì˜ˆ: product -> db_id)
        self.categories_config = batch_config.get("categories", {})
        self.database_ids = {
            k: v["db_id"] for k, v in self.categories_config.items() if "db_id" in v
        }

        # ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê·œì¹™ ì£¼ì…
        self._setup_schema_validation(metadata_config)
        self.field_aliases = metadata_config.get("field_aliases", {})

        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        self.prompts = self._load_prompts()

        # í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.notion_api_key = notion_api_key or os.getenv("NOTION_API_KEY")
        if not self.notion_api_key:
            raise ValueError("NOTION_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.notion_client = NotionAPIClient(api_key=self.notion_api_key)

        self.openrouter_api_key = openrouter_api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.openrouter_api_key:
            raise ValueError("OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.llm_client = AsyncOpenAI(
            api_key=self.openrouter_api_key,
            base_url="https://openrouter.ai/api/v1",
        )

        self.model = model
        self.output_dir = Path(output_dir)

        logger.info(
            f"âœ… NotionMetadataExtractor ì´ˆê¸°í™” ì™„ë£Œ (model={model}, "
            f"categories={list(self.database_ids.keys())})"
        )

    def _setup_schema_validation(self, metadata_config: dict[str, Any]):
        """ë²”ìš© ìŠ¤í‚¤ë§ˆì— ê²€ì¦ ê·œì¹™ ì„¤ì •"""
        required = metadata_config.get("required_fields", ["name"])
        numeric = metadata_config.get("numeric_fields", [])
        boolean = metadata_config.get("boolean_fields", [])

        GenericMetadataSchema.set_validation_rules(
            required=required,
            numeric=numeric,
            boolean=boolean
        )
        logger.info("ğŸ”§ ë²”ìš© ìŠ¤í‚¤ë§ˆ ê²€ì¦ ê·œì¹™ ì„¤ì • ì™„ë£Œ")

    def _load_prompts(self) -> dict[str, str]:
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
        prompt_path = Path("data/prompts/extraction_prompts.json")
        if prompt_path.exists():
            try:
                with open(prompt_path, encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {}
        return {}

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.notion_client.close()

    # =========================================================================
    # í•µì‹¬ ì¶”ì¶œ ë©”ì„œë“œ
    # =========================================================================

    async def extract_category(
        self,
        category: str,
        limit: int | None = None,
        save_results: bool = True,
    ) -> BatchResult:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        """
        import time
        start_time = time.time()

        if category not in self.database_ids:
            raise ValueError(f"ì„¤ì •ë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {category}")

        database_id = self.database_ids[category]
        logger.info(f"ğŸš€ '{category}' ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œì‘ (DB: {database_id})")

        # 1. Notion ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
        db_result = await self.notion_client.query_database(database_id)
        pages = db_result.pages

        if limit:
            pages = pages[:limit]
            logger.info(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {limit}ê°œ í˜ì´ì§€ë§Œ ì²˜ë¦¬")

        # 2. ê° í˜ì´ì§€ ì²˜ë¦¬
        results: list[ExtractionResult] = []
        success_count = 0

        for idx, page in enumerate(pages, 1):
            logger.info(f"  [{idx}/{len(pages)}] ì²˜ë¦¬ ì¤‘: {page.title}")

            try:
                result = await self._extract_single_page(page, category)
                results.append(result)

                if result.error is None:
                    success_count += 1
                    logger.info(
                        f"    âœ… ì¶”ì¶œ ì™„ë£Œ: {result.extraction_rate:.1f}% "
                        f"({result.filled_fields}/{result.total_fields} í•„ë“œ)"
                    )
                else:
                    logger.warning(f"    âš ï¸ ì¶”ì¶œ ì‹¤íŒ¨: {result.error}")

                # Rate Limit ë°©ì§€
                await asyncio.sleep(0.5)

            except Exception as e:
                logger.error(f"    âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
                results.append(ExtractionResult(
                    entity_name=page.title,
                    category=category,
                    page_id=page.id,
                    extraction_rate=0.0,
                    filled_fields=0,
                    total_fields=0,
                    metadata={},
                    error=str(e),
                ))

        # 3. ê²°ê³¼ ì €ì¥
        if save_results:
            await self._save_results(category, results)

        # 4. í†µê³„ ê³„ì‚°
        duration = time.time() - start_time
        avg_rate = sum(r.extraction_rate for r in results) / len(results) if results else 0.0

        return BatchResult(
            category=category,
            total_pages=len(pages),
            success_count=success_count,
            failed_count=len(pages) - success_count,
            average_extraction_rate=avg_rate,
            results=results,
            duration_seconds=duration,
        )

    async def _extract_single_page(
        self,
        page: NotionPage,
        category: str,
    ) -> ExtractionResult:
        """ë‹¨ì¼ í˜ì´ì§€ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        # 1. í˜ì´ì§€ ë³¸ë¬¸ ì½˜í…ì¸  ì¡°íšŒ
        content = await self.notion_client.get_page_content(page.id)
        properties_text = self._properties_to_text(page.properties)
        full_content = f"ì œëª©: {page.title}\n\n{properties_text}\n\n{content}"

        if not full_content.strip():
            return ExtractionResult(
                entity_name=page.title,
                category=category,
                page_id=page.id,
                extraction_rate=0.0,
                filled_fields=0,
                total_fields=0,
                metadata={},
                raw_content="",
                error="ì½˜í…ì¸  ì—†ìŒ",
            )

        # 2. LLMìœ¼ë¡œ êµ¬ì¡°í™” ì¶”ì¶œ
        extracted_data = await self._call_llm(full_content, category)

        if extracted_data is None:
            return ExtractionResult(
                entity_name=page.title,
                category=category,
                page_id=page.id,
                extraction_rate=0.0,
                filled_fields=0,
                total_fields=0,
                metadata={},
                raw_content=full_content[:500],
                error="LLM ì¶”ì¶œ ì‹¤íŒ¨",
            )

        # 3. ì´ë¦„ í•„ë“œ ê°•ì œ ì„¤ì • (ë³„ì¹­ ì‚¬ìš©)
        # categoryì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ í•„ë“œë¥¼ ì°¾ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ page.titleì„ nameìœ¼ë¡œ ì‚¬ìš©
        extracted_data["name"] = page.title
        extracted_data["category"] = category

        # 4. GenericMetadataSchemaë¡œ ê²€ì¦
        try:
            # ë™ì  ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
            validated = GenericMetadataSchema.model_validate(extracted_data)

            # ë³„ì¹­ ì ìš©í•˜ì—¬ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„± (ì„ íƒ ì‚¬í•­)
            # ì—¬ê¸°ì„œëŠ” ì›ë³¸ í‚¤ë¥¼ ìœ ì§€í•˜ë˜, í•„ìš”í•œ ê²½ìš° display_dict ì‚¬ìš©
            metadata = validated.model_dump()

            filled, total = validated.get_filled_field_count()
            rate = validated.get_extraction_rate()

            return ExtractionResult(
                entity_name=page.title,
                category=category,
                page_id=page.id,
                extraction_rate=rate,
                filled_fields=filled,
                total_fields=total,
                metadata=metadata,
                raw_content=full_content[:500],
            )

        except ValidationError as e:
            return ExtractionResult(
                entity_name=page.title,
                category=category,
                page_id=page.id,
                extraction_rate=0.0,
                filled_fields=0,
                total_fields=0,
                metadata=extracted_data,
                raw_content=full_content[:500],
                error=f"ê²€ì¦ ì‹¤íŒ¨: {str(e)[:100]}",
            )

    def _properties_to_text(self, properties: dict[str, Any]) -> str:
        """Notion ì†ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = []
        for key, value in properties.items():
            if value:
                if isinstance(value, list):
                    value = ", ".join(str(v) for v in value)
                lines.append(f"{key}: {value}")
        return "\n".join(lines)

    async def _call_llm(self, content: str, category: str) -> dict | None:
        """LLM í˜¸ì¶œ"""
        # ì¹´í…Œê³ ë¦¬ë³„ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì œê³µ)
        prompt_template = self.prompts.get(category, self.prompts.get("default", ""))

        # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ë§¤ìš° ê¸°ë³¸ì  í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if not prompt_template:
            prompt_template = (
                "ì•„ë˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
                "ì •ë³´:\n{content}\n\nJSON:"
            )

        # í…œí”Œë¦¿ í¬ë§·íŒ… (category_name ë“± ì£¼ì…)
        category_name = self.categories_config.get(category, {}).get("category_name", category)
        prompt = prompt_template.format(
            content=content[:8000], # í† í° ì œí•œ
            category_name=category_name
        )

        try:
            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a JSON extraction expert. Output valid JSON only."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=4000,
            )
            raw = response.choices[0].message.content or ""
            return self._parse_json_response(raw)
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _parse_json_response(self, response: str) -> dict | None:
        """JSON íŒŒì‹± (ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬ í¬í•¨)"""
        # 1. ```json ... ``` ì œê±°
        if "```" in response:
            parts = response.split("```")
            for part in parts:
                if "{" in part:
                    response = part
                    if response.startswith("json"):
                        response = response[4:]
                    break

        try:
            return json.loads(response.strip())
        except json.JSONDecodeError:
            return None

    async def _save_results(self, category: str, results: list[ExtractionResult]):
        """ê²°ê³¼ ì €ì¥"""
        output_path = self.output_dir / category
        output_path.mkdir(parents=True, exist_ok=True)

        for result in results:
            if result.entity_name:
                safe_name = re.sub(r'[\\/*?:\"<>|]', "", result.entity_name)
                file_path = output_path / f"{safe_name}.json"

                data = {
                    "entity_name": result.entity_name,
                    "category": result.category,
                    "page_id": result.page_id,
                    "extraction_rate": result.extraction_rate,
                    "filled_fields": result.filled_fields,
                    "total_fields": result.total_fields,
                    "metadata": result.metadata,
                    "extracted_at": result.extracted_at,
                }
                if result.error:
                    data["error"] = result.error

                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

# =============================================================================
# CLI ì‹¤í–‰
# =============================================================================

async def main():
    import argparse
    parser = argparse.ArgumentParser(description="Notion API ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë²”ìš©)")
    parser.add_argument("--category", default="all", help="ì¶”ì¶œí•  ì¹´í…Œê³ ë¦¬ í‚¤ (domain.yaml ì°¸ì¡°)")
    parser.add_argument("--limit", type=int, default=None, help="í…ŒìŠ¤íŠ¸ìš© í˜ì´ì§€ ì œí•œ")
    parser.add_argument("--model", default="anthropic/claude-sonnet-4", help="ì‚¬ìš©í•  LLM ëª¨ë¸")

    args = parser.parse_args()
    extractor = NotionMetadataExtractor(model=args.model)

    try:
        # ì„¤ì •ëœ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°
        available_categories = list(extractor.database_ids.keys())

        if args.category == "all":
            categories = available_categories
        else:
            if args.category not in available_categories:
                print(f"âŒ ì˜¤ë¥˜: '{args.category}'ëŠ” ì„¤ì •ëœ ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
                print(f"ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {available_categories}")
                return
            categories = [args.category]

        for category in categories:
            await extractor.extract_category(category, limit=args.limit)

    finally:
        await extractor.close()

if __name__ == "__main__":
    asyncio.run(main())
