"""
Configuration Schemas - Pydantic ê¸°ë°˜ ì„¤ì • ê²€ì¦
YAML ì„¤ì •ì„ íƒ€ì… ì•ˆì „í•˜ê²Œ ê²€ì¦í•˜ê³  IDE ìë™ì™„ì„± ì§€ì›
"""

import re
from typing import Any, Literal

from pydantic import BaseModel, ConfigDict, Field, model_validator

# ========================================
# App & Server Configuration
# ========================================


class AppConfig(BaseModel):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì„¤ì •"""

    name: str = Field(..., min_length=1)
    version: str = Field(..., pattern=r"^\d+\.\d+\.\d+$")
    environment: Literal["development", "production", "test"] = "development"
    debug: bool = False


class ServerConfig(BaseModel):
    """ì„œë²„ ì„¤ì •"""

    host: str = Field(default="0.0.0.0")
    port: int = Field(default=8000, ge=1, le=65535)
    workers: int = Field(default=1, ge=1)
    reload: bool = False


# ========================================
# LLM Configuration
# ========================================


class LLMProviderConfig(BaseModel):
    """ê°œë³„ LLM ì œê³µì ì„¤ì •"""

    model: str = Field(..., min_length=1)
    api_key: str | None = Field(default=None)
    temperature: float = Field(default=0.0, ge=0.0, le=2.0)
    max_tokens: int = Field(default=2048, ge=1)
    timeout: int = Field(default=30, ge=1)
    max_retries: int = Field(default=3, ge=0)


class LLMConfig(BaseModel):
    """LLM í†µí•© ì„¤ì •"""

    default_provider: Literal["google", "openai", "anthropic", "openrouter"] = "google"
    auto_fallback: bool = True  # í•„ë“œëª… ìˆ˜ì •
    fallback_order: list[str] | None = None
    google: LLMProviderConfig
    openai: LLMProviderConfig
    anthropic: LLMProviderConfig

    # providers ë¦¬ìŠ¤íŠ¸ëŠ” ë¬´ì‹œ (í•˜ìœ„ í˜¸í™˜ì„±)
    model_config = {"extra": "allow"}


# ========================================
# Retrieval Configuration
# ========================================


class EmbeddingsConfig(BaseModel):
    """ì„ë² ë”© ì„¤ì •"""

    model_config = ConfigDict(extra="allow")  # output_dimensionality, batch_size ë“± ì¶”ê°€ í•„ë“œ í—ˆìš©

    provider: Literal["google", "openai", "openrouter"] = "google"
    model: str = Field(default="text-embedding-004")
    api_key: str | None = None
    dimension: int = Field(default=768, ge=1)
    output_dimensionality: int | None = Field(default=None, ge=1)  # ì„ íƒì  í•„ë“œ
    batch_size: int | None = Field(default=None, ge=1)  # ì„ íƒì  í•„ë“œ
    task_type: str | None = None  # Google Geminiìš©


class RetrievalConfig(BaseModel):
    """ê²€ìƒ‰ ì„¤ì •"""

    max_sources: int = Field(default=15, ge=1)
    min_score: float = Field(default=0.05, ge=0.0, le=1.0)
    hybrid_alpha: float = Field(default=0.6, ge=0.0, le=1.0)
    top_k: int = Field(default=15, ge=1)


# ========================================
# Reranking Configuration
# ========================================


class RerankingConfig(BaseModel):
    """ë¦¬ë­í‚¹ ì„¤ì •"""

    model_config = ConfigDict(extra="allow")  # providers ë“± ì¶”ê°€ í•„ë“œ í—ˆìš©

    enabled: bool = True
    default_provider: Literal["jina", "cohere", "llm", "gemini_flash", "openrouter_gemini"] = (
        "gemini_flash"
    )
    api_key: str | None = None
    top_n: int = Field(default=15, ge=1)
    min_score: float = Field(default=0.05, ge=0.0, le=1.0)


# ========================================
# Query Routing Configuration
# ========================================


class LLMRouterConfig(BaseModel):
    """LLM ë¼ìš°í„° ì„¤ì •"""

    enabled: bool = True  # ğŸ†• LLM ë¼ìš°í„° í™œì„±í™” í”Œë˜ê·¸
    provider: Literal["google", "openrouter"] = "google"
    model: str = Field(default="gemini-2.0-flash-lite")
    temperature: float = Field(default=0.0, ge=0.0, le=2.0)
    max_tokens: int = Field(default=1024, ge=1)


class QueryRoutingConfig(BaseModel):
    """ì¿¼ë¦¬ ë¼ìš°íŒ… ì„¤ì •"""

    enabled: bool = False
    llm_router: LLMRouterConfig
    cache_ttl: int = Field(default=3600, ge=0)


# ========================================
# Phase 2: BM25 ê³ ë„í™” Configuration
# ========================================


class BM25SynonymConfig(BaseModel):
    """ë™ì˜ì–´ ì‚¬ì „ ì„¤ì •"""

    enabled: bool = True
    csv_path: str = Field(default="docs/phase2/ì±—ë´‡ - ë™ì˜ì–´ ì‚¬ì „.csv")
    expand_query: bool = True


class BM25StopwordConfig(BaseModel):
    """ë¶ˆìš©ì–´ í•„í„° ì„¤ì •"""

    enabled: bool = True
    use_defaults: bool = True
    custom: list[str] = Field(default_factory=list)


class BM25UserDictionaryConfig(BaseModel):
    """ì‚¬ìš©ì ì‚¬ì „ ì„¤ì •"""

    enabled: bool = True
    use_defaults: bool = True
    custom: list[str] = Field(default_factory=list)


class BM25Config(BaseModel):
    """BM25 ê³ ë„í™” í†µí•© ì„¤ì •"""

    enabled: bool = True
    synonym: BM25SynonymConfig = Field(default_factory=BM25SynonymConfig)
    stopword: BM25StopwordConfig = Field(default_factory=BM25StopwordConfig)
    user_dictionary: BM25UserDictionaryConfig = Field(default_factory=BM25UserDictionaryConfig)


# ========================================
# Phase 2: Privacy Configuration
# ========================================


class PrivacyMaskingConfig(BaseModel):
    """ë§ˆìŠ¤í‚¹ ëŒ€ìƒ ì„¤ì •"""

    phone: bool = True  # ê°œì¸ ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    name: bool = True  # ì´ë¦„ ë§ˆìŠ¤í‚¹
    email: bool = False  # ì´ë©”ì¼ ë§ˆìŠ¤í‚¹ (ê¸°ë³¸ ë¹„í™œì„±í™”)


class PrivacyCharactersConfig(BaseModel):
    """ë§ˆìŠ¤í‚¹ ë¬¸ì ì„¤ì •"""

    phone: str = "*"
    name: str = "*"


class PrivacyExceptionsConfig(BaseModel):
    """ì˜ˆì™¸ ì²˜ë¦¬ ì„¤ì •"""

    phone_prefixes: list[str] = Field(
        default_factory=lambda: [
            "02",
            "031",
            "032",
            "033",
            "041",
            "042",
            "043",
            "044",
            "051",
            "052",
            "053",
            "054",
            "055",
            "061",
            "062",
            "063",
            "064",
        ]
    )


class PrivacyConfig(BaseModel):
    """ê°œì¸ì •ë³´ ë³´í˜¸ í†µí•© ì„¤ì •"""

    enabled: bool = True
    masking: PrivacyMaskingConfig = Field(default_factory=PrivacyMaskingConfig)
    characters: PrivacyCharactersConfig = Field(default_factory=PrivacyCharactersConfig)
    exceptions: PrivacyExceptionsConfig = Field(default_factory=PrivacyExceptionsConfig)


# ========================================
# Self-RAG Configuration
# ========================================


class SelfRAGEvaluationConfig(BaseModel):
    """Self-RAG í‰ê°€ ëª¨ë“ˆ ì„¤ì •"""

    provider: Literal["google", "openai", "anthropic", "openrouter"] = "google"
    model: str = Field(default="gemini-2.0-flash-lite")
    api_key: str | None = None
    temperature: float = Field(default=0.0, ge=0.0, le=2.0)
    max_tokens: int = Field(default=500, ge=1)
    timeout: int = Field(default=10, ge=1)
    max_retries: int = Field(default=3, ge=0)
    retry_delay: float = Field(default=0.5, ge=0.0)
    retry_exponential_base: int = Field(default=2, ge=1)
    enable_caching: bool = False


class SelfRAGReRetrievalConfig(BaseModel):
    """Self-RAG ì¬ê²€ìƒ‰ ì„¤ì •"""

    strategy: Literal["issue_based", "query_expansion", "hybrid"] = "issue_based"
    max_additional_docs: int = Field(default=5, ge=1)
    min_relevance_score: float = Field(default=0.05, ge=0.0, le=1.0)
    merge_strategy: Literal["append", "replace"] = "append"


class SelfRAGMonitoringConfig(BaseModel):
    """Self-RAG ëª¨ë‹ˆí„°ë§ ì„¤ì •"""

    enable_metrics: bool = True
    log_evaluations: bool = True
    log_level: Literal["DEBUG", "INFO", "WARNING", "ERROR"] = "INFO"
    tracked_metrics: list[str] = Field(
        default_factory=lambda: [
            "complexity_distribution",
            "quality_scores",
            "regeneration_rate",
            "improvement_delta",
            "evaluation_time",
            "total_processing_time",
            "cost_per_query",
        ]
    )


class SelfRAGCostControlConfig(BaseModel):
    """Self-RAG ë¹„ìš© ì œì–´ ì„¤ì •"""

    enable_budget_limit: bool = False
    daily_budget_usd: float = Field(default=10.0, ge=0.0)
    auto_disable_on_budget_exceeded: bool = False
    alert_threshold: float = Field(default=0.8, ge=0.0, le=1.0)


class SelfRAGDevelopmentConfig(BaseModel):
    """Self-RAG ê°œë°œ ì„¤ì •"""

    enable_debug_mode: bool = False
    log_prompts: bool = False
    save_evaluation_history: bool = True
    max_history_entries: int = Field(default=1000, ge=1)


class SelfRAGConfig(BaseModel):
    """Self-RAG í†µí•© ì„¤ì •"""

    enabled: bool = False
    complexity_threshold: float = Field(default=0.7, ge=0.0, le=1.0)
    quality_threshold: float = Field(default=0.8, ge=0.0, le=1.0)
    max_iterations: int = Field(default=1, ge=1, le=3)
    enable_rollback: bool = True
    rollback_threshold: float = Field(default=-0.1, ge=-1.0, le=0.0)
    response_mode: Literal["batch", "streaming"] = "batch"

    # Self-RAG Orchestrator íŒŒë¼ë¯¸í„° (DI Container í˜¸í™˜)
    initial_top_k: int = Field(
        default=5, ge=1, le=50, description="ì´ˆê¸° ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (Self-RAG ì ìš© ì „)"
    )
    retry_top_k: int = Field(
        default=15, ge=1, le=100, description="ì¬ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (í’ˆì§ˆì´ ë‚®ì„ ë•Œ)"
    )
    max_retries: int = Field(default=1, ge=0, le=3, description="ìµœëŒ€ ì¬ìƒì„± íšŸìˆ˜ (0=ì¬ìƒì„± ì—†ìŒ)")

    evaluation: SelfRAGEvaluationConfig
    re_retrieval: SelfRAGReRetrievalConfig
    monitoring: SelfRAGMonitoringConfig
    cost_control: SelfRAGCostControlConfig
    development: SelfRAGDevelopmentConfig


# ========================================
# Root Configuration
# ========================================


class RootConfig(BaseModel):
    """ë£¨íŠ¸ ì„¤ì • - ì „ì²´ ì‹œìŠ¤í…œ ì„¤ì •"""

    app: AppConfig
    server: ServerConfig
    llm: LLMConfig
    embeddings: EmbeddingsConfig
    retrieval: RetrievalConfig
    reranking: RerankingConfig
    query_routing: QueryRoutingConfig
    self_rag: SelfRAGConfig

    # Phase 2: BM25 ê³ ë„í™” ë° ê°œì¸ì •ë³´ ë³´í˜¸
    bm25: BM25Config = Field(default_factory=BM25Config)
    privacy: PrivacyConfig = Field(default_factory=PrivacyConfig)

    # ì¶”ê°€ ì„¤ì •ì€ ëŠìŠ¨í•˜ê²Œ í—ˆìš©
    model_config = {"extra": "allow"}

    @model_validator(mode="after")
    def validate_api_keys(self):
        """í™œì„±í™”ëœ ê¸°ëŠ¥ì˜ API í‚¤ ê²€ì¦"""
        errors = []

        # LLM ì œê³µì API í‚¤ ê²€ì¦
        for provider_name in ["google", "openai", "anthropic"]:
            provider_config = getattr(self.llm, provider_name, None)
            if provider_config and not provider_config.api_key:
                errors.append(f"LLM {provider_name} API í‚¤ ëˆ„ë½")

        # ì„ë² ë”© API í‚¤ ê²€ì¦
        if not self.embeddings.api_key:
            errors.append("ì„ë² ë”© API í‚¤ ëˆ„ë½")

        # ë¦¬ë­í‚¹ API í‚¤ ê²€ì¦ (í™œì„±í™” ì‹œ)
        if self.reranking.enabled and not self.reranking.api_key:
            if self.reranking.default_provider in ["jina", "cohere"]:
                errors.append(f"ë¦¬ë­í‚¹ {self.reranking.default_provider} API í‚¤ ëˆ„ë½")

        # Self-RAG API í‚¤ ê²€ì¦ (í™œì„±í™” ì‹œ)
        if self.self_rag.enabled and not self.self_rag.evaluation.api_key:
            errors.append("Self-RAG í‰ê°€ ëª¨ë“ˆ API í‚¤ ëˆ„ë½")

        if errors:
            print(f"âš ï¸  API í‚¤ ê²½ê³ : {', '.join(errors)}")
            # ê²½ê³ ë§Œ ì¶œë ¥, ì—ëŸ¬ëŠ” ë°œìƒì‹œí‚¤ì§€ ì•ŠìŒ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œê³µ ê°€ëŠ¥)

        return self

    @model_validator(mode="after")
    def validate_self_rag_consistency(self):
        """Self-RAG ì„¤ì • ì¼ê´€ì„± ê²€ì¦"""
        if self.self_rag.enabled:
            # í’ˆì§ˆ ì„ê³„ê°’ì´ ë³µì¡ë„ ì„ê³„ê°’ë³´ë‹¤ ë†’ì•„ì•¼ í•¨
            if self.self_rag.quality_threshold <= self.self_rag.complexity_threshold:
                raise ValueError(
                    f"quality_threshold({self.self_rag.quality_threshold})ëŠ” "
                    f"complexity_threshold({self.self_rag.complexity_threshold})ë³´ë‹¤ ë†’ì•„ì•¼ í•¨"
                )

            # ì˜ˆì‚° ì œì–´ í™œì„±í™” ì‹œ ì˜ˆì‚° ê°’ ê²€ì¦
            if self.self_rag.cost_control.enable_budget_limit:
                if self.self_rag.cost_control.daily_budget_usd <= 0:
                    raise ValueError("daily_budget_usdëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•¨")

        return self


# ========================================
# Helper Functions
# ========================================


def validate_config_dict(config_dict: dict[str, Any]) -> RootConfig:
    """
    ë”•ì…”ë„ˆë¦¬ë¥¼ Pydantic ëª¨ë¸ë¡œ ê²€ì¦

    Args:
        config_dict: YAMLì—ì„œ ë¡œë“œí•œ ì„¤ì • ë”•ì…”ë„ˆë¦¬

    Returns:
        ê²€ì¦ëœ RootConfig ê°ì²´

    Raises:
        ValidationError: ì„¤ì • ê²€ì¦ ì‹¤íŒ¨ ì‹œ
    """
    return RootConfig.model_validate(config_dict)


def detect_duplicate_keys_in_yaml(yaml_path: str) -> list[str]:
    """
    YAML íŒŒì¼ì—ì„œ ì¤‘ë³µëœ ìµœìƒìœ„ í‚¤ íƒì§€

    Args:
        yaml_path: YAML íŒŒì¼ ê²½ë¡œ

    Returns:
        ì¤‘ë³µëœ í‚¤ ëª©ë¡
    """
    with open(yaml_path, encoding="utf-8") as f:
        lines = f.readlines()

    # ìµœìƒìœ„ í‚¤ë§Œ ì¶”ì¶œ (ë“¤ì—¬ì“°ê¸° ì—†ëŠ” í‚¤)
    top_level_pattern = re.compile(r"^([a-zA-Z_][a-zA-Z0-9_]*):\s*")
    keys_seen: dict[str, int] = {}
    duplicates = []

    for i, line in enumerate(lines, start=1):
        match = top_level_pattern.match(line)
        if match:
            key = match.group(1)
            if key in keys_seen:
                duplicates.append(f"{key} (ì²« ë²ˆì§¸: {keys_seen[key]}ì¤„, ì¤‘ë³µ: {i}ì¤„)")
            else:
                keys_seen[key] = i

    return duplicates
