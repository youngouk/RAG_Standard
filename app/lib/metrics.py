"""
Metrics Collection System
ë¹„ìš© ì¶”ì  + ì„±ëŠ¥ ë©”íŠ¸ë¦­ í†µí•© ì‹œìŠ¤í…œ
"""

import time
from dataclasses import dataclass, field
from datetime import datetime
from threading import Lock
from typing import Any

from .logger import get_logger

logger = get_logger(__name__)


# ========================================
# ë¹„ìš© ì¶”ì 
# ========================================


@dataclass
class CostTracker:
    """LLM API ë¹„ìš© ì¶”ì ê¸°"""

    # ì œê³µìë³„ ë¹„ìš© (USD / 1M tokens)
    COST_PER_MILLION_TOKENS = {
        "google": {
            "input": 0.125,  # Gemini 2.0 Flash input
            "output": 0.5,  # Gemini 2.0 Flash output
        },
        "openai": {
            "input": 2.5,  # GPT-4o input
            "output": 10.0,  # GPT-4o output
        },
        "anthropic": {
            "input": 3.0,  # Claude 3.5 Sonnet input
            "output": 15.0,  # Claude 3.5 Sonnet output
        },
    }

    # ëˆ„ì  í† í° ì‚¬ìš©ëŸ‰
    total_tokens: dict[str, int] = field(
        default_factory=lambda: {"google": 0, "openai": 0, "anthropic": 0}
    )

    # ëˆ„ì  ë¹„ìš© (USD)
    total_cost: dict[str, float] = field(
        default_factory=lambda: {"google": 0.0, "openai": 0.0, "anthropic": 0.0}
    )

    # ìš”ì²­ ìˆ˜
    request_count: dict[str, int] = field(
        default_factory=lambda: {"google": 0, "openai": 0, "anthropic": 0}
    )

    # ì‹œì‘ ì‹œê°„
    start_time: datetime = field(default_factory=datetime.now)

    # Thread-safe
    _lock: Lock = field(default_factory=Lock)

    def track_usage(self, provider: str, tokens_used: int, is_input: bool = False) -> None:
        """
        í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡

        Args:
            provider: LLM ì œê³µì (google, openai, anthropic)
            tokens_used: ì‚¬ìš©ëœ í† í° ìˆ˜
            is_input: Trueë©´ input í† í°, Falseë©´ output í† í°
        """
        with self._lock:
            if provider not in self.total_tokens:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì œê³µì: {provider}")
                return

            # í† í° ëˆ„ì 
            self.total_tokens[provider] += tokens_used
            self.request_count[provider] += 1

            # ë¹„ìš© ê³„ì‚°
            token_type = "input" if is_input else "output"
            cost_per_million = self.COST_PER_MILLION_TOKENS[provider][token_type]
            cost = (tokens_used / 1_000_000) * cost_per_million

            self.total_cost[provider] += cost

            logger.debug(
                f"ğŸ’° ë¹„ìš© ì¶”ì : {provider} {token_type} " f"{tokens_used} tokens = ${cost:.4f}"
            )

    def get_summary(self) -> dict[str, Any]:
        """ë¹„ìš© ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        with self._lock:
            total_tokens_all = sum(self.total_tokens.values())
            total_cost_all = sum(self.total_cost.values())
            total_requests_all = sum(self.request_count.values())

            elapsed_hours = (datetime.now() - self.start_time).total_seconds() / 3600

            return {
                "total_cost_usd": round(total_cost_all, 4),
                "total_tokens": total_tokens_all,
                "total_requests": total_requests_all,
                "elapsed_hours": round(elapsed_hours, 2),
                "cost_per_hour": (
                    round(total_cost_all / elapsed_hours, 4) if elapsed_hours > 0 else 0
                ),
                "by_provider": {
                    provider: {
                        "tokens": self.total_tokens[provider],
                        "cost_usd": round(self.total_cost[provider], 4),
                        "requests": self.request_count[provider],
                    }
                    for provider in ["google", "openai", "anthropic"]
                },
                "start_time": self.start_time.isoformat(),
            }

    def reset(self) -> None:
        """í†µê³„ ë¦¬ì…‹"""
        with self._lock:
            self.total_tokens = dict.fromkeys(self.total_tokens, 0)
            self.total_cost = dict.fromkeys(self.total_cost, 0.0)
            self.request_count = dict.fromkeys(self.request_count, 0)
            self.start_time = datetime.now()
            logger.info("ğŸ”„ ë¹„ìš© ì¶”ì  í†µê³„ ë¦¬ì…‹")


# ========================================
# ì„±ëŠ¥ ë©”íŠ¸ë¦­
# ========================================


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""

    # í•¨ìˆ˜ë³„ ë©”íŠ¸ë¦­
    function_metrics: dict[str, list[float]] = field(default_factory=dict)

    # ì—ëŸ¬ ì¹´ìš´íŠ¸
    error_counts: dict[str, int] = field(default_factory=dict)

    # Thread-safe
    _lock: Lock = field(default_factory=Lock)

    def record_latency(self, function_name: str, latency_ms: float) -> None:
        """
        ì‘ë‹µ ì‹œê°„ ê¸°ë¡

        Args:
            function_name: í•¨ìˆ˜ ì´ë¦„
            latency_ms: ì‘ë‹µ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
        """
        with self._lock:
            if function_name not in self.function_metrics:
                self.function_metrics[function_name] = []

            self.function_metrics[function_name].append(latency_ms)

            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(self.function_metrics[function_name]) > 100:
                self.function_metrics[function_name].pop(0)

    def record_error(self, function_name: str) -> None:
        """ì—ëŸ¬ ê¸°ë¡"""
        with self._lock:
            if function_name not in self.error_counts:
                self.error_counts[function_name] = 0

            self.error_counts[function_name] += 1

    def get_stats(self, function_name: str) -> dict[str, Any]:
        """í•¨ìˆ˜ë³„ í†µê³„ ë°˜í™˜"""
        with self._lock:
            latencies = self.function_metrics.get(function_name, [])

            if not latencies:
                return {
                    "function": function_name,
                    "count": 0,
                    "avg_latency_ms": 0,
                    "min_latency_ms": 0,
                    "max_latency_ms": 0,
                    "p95_latency_ms": 0,
                    "errors": 0,
                }

            sorted_latencies = sorted(latencies)
            count = len(latencies)
            p95_index = int(count * 0.95)

            return {
                "function": function_name,
                "count": count,
                "avg_latency_ms": round(sum(latencies) / count, 2),
                "min_latency_ms": round(min(latencies), 2),
                "max_latency_ms": round(max(latencies), 2),
                "p95_latency_ms": round(sorted_latencies[p95_index], 2) if p95_index < count else 0,
                "errors": self.error_counts.get(function_name, 0),
            }

    def get_all_stats(self) -> dict[str, Any]:
        """ëª¨ë“  í•¨ìˆ˜ í†µê³„ ë°˜í™˜"""
        with self._lock:
            return {fn: self.get_stats(fn) for fn in self.function_metrics.keys()}

    def reset(self) -> None:
        """í†µê³„ ë¦¬ì…‹"""
        with self._lock:
            self.function_metrics.clear()
            self.error_counts.clear()
            logger.info("ğŸ”„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í†µê³„ ë¦¬ì…‹")


# ========================================
# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
# ========================================

_global_performance_metrics: PerformanceMetrics | None = None


def get_performance_metrics() -> PerformanceMetrics:
    """
    ì „ì—­ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°

    .. deprecated:: 3.1.0
        DI Containerì˜ AppContainer.performance_metricsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        ì´ í•¨ìˆ˜ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ë©° v4.0.0ì—ì„œ ì œê±°ë  ì˜ˆì •ì…ë‹ˆë‹¤.

    Returns:
        PerformanceMetrics: ì „ì—­ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤

    Example (Deprecated):
        metrics = get_performance_metrics()
        metrics.record_latency('retrieval', 150.5)

    Example (Recommended):
        from app.core.di_container import AppContainer

        container = AppContainer()
        metrics = container.performance_metrics()
        metrics.record_latency('retrieval', 150.5)
    """
    import warnings

    warnings.warn(
        "get_performance_metrics()ëŠ” deprecatedë˜ì—ˆìŠµë‹ˆë‹¤. "
        "DI Containerì˜ AppContainer.performance_metricsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
        DeprecationWarning,
        stacklevel=2,
    )
    global _global_performance_metrics
    if _global_performance_metrics is None:
        _global_performance_metrics = PerformanceMetrics()
        logger.info("âœ… ì „ì—­ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”")
    return _global_performance_metrics


# ========================================
# í—¬í¼ í•¨ìˆ˜
# ========================================


def track_function_performance(function_name: str) -> Any:
    """í•¨ìˆ˜ ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""

    def decorator(func: Any) -> Any:
        async def wrapper(*args: Any, **kwargs: Any) -> Any:
            start_time = time.time()
            metrics = get_performance_metrics()

            try:
                result = await func(*args, **kwargs)
                latency_ms = (time.time() - start_time) * 1000
                metrics.record_latency(function_name, latency_ms)
                return result
            except Exception:
                metrics.record_error(function_name)
                raise

        return wrapper

    return decorator


# ========================================
# í˜¸í™˜ì„± Export
# ========================================

# rag_pipeline.py í˜¸í™˜ì„±ì„ ìœ„í•œ ì „ì—­ metrics ê°ì²´
metrics = get_performance_metrics()
