# Documents Module - ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ

MVP Phase ë¬¸ì„œ ìœ í˜•ë³„ ì²˜ë¦¬ ì „ëµì„ ì œê³µí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
documents/
â”œâ”€â”€ __init__.py                  # ëª¨ë“ˆ ì§„ì…ì 
â”œâ”€â”€ base.py                      # BaseDocumentProcessor (ì¶”ìƒ ë² ì´ìŠ¤)
â”œâ”€â”€ factory.py                   # DocumentProcessorFactory (íŒ©í† ë¦¬ íŒ¨í„´)
â”œâ”€â”€ document_processing.py       # ê¸°ì¡´ DocumentProcessor (Low-level)
â”‚
â”œâ”€â”€ models/                      # ë°ì´í„° ëª¨ë¸
â”‚   â”œâ”€â”€ document.py              # Document í´ë˜ìŠ¤
â”‚   â””â”€â”€ chunk.py                 # Chunk í´ë˜ìŠ¤
â”‚
â”œâ”€â”€ chunking/                    # ì²­í‚¹ ì „ëµ (Strategy íŒ¨í„´)
â”‚   â”œâ”€â”€ base.py                  # BaseChunker
â”‚   â””â”€â”€ simple_chunker.py        # SimpleChunker (FAQìš©)
â”‚
â”œâ”€â”€ metadata/                    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (Strategy íŒ¨í„´)
â”‚   â”œâ”€â”€ base.py                  # BaseMetadataExtractor
â”‚   â””â”€â”€ rule_based.py            # RuleBasedExtractor (ê·œì¹™ ê¸°ë°˜)
â”‚
â”œâ”€â”€ processors/                  # ë¬¸ì„œ ìœ í˜•ë³„ í”„ë¡œì„¸ì„œ
â”‚   â””â”€â”€ faq_processor.py         # FAQProcessor (MVP)
â”‚
â””â”€â”€ loaders/                     # íŒŒì¼ ë¡œë” (ê¸°ì¡´)
    â”œâ”€â”€ base.py
    â”œâ”€â”€ factory.py
    â””â”€â”€ ... (ë‹¤ì–‘í•œ ë¡œë”)
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. FAQ ë¬¸ì„œ ì²˜ë¦¬ (MVP)

```python
from app.modules.core.documents import DocumentProcessorFactory

# 1. íŒ©í† ë¦¬ë¡œ í”„ë¡œì„¸ì„œ ìƒì„±
processor = DocumentProcessorFactory.create('faq')

# 2. FAQ íŒŒì¼ ì²˜ë¦¬
chunks = processor.process('data/FAQ.xlsx')

# 3. ê²°ê³¼ í™•ì¸
print(f"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
for chunk in chunks[:3]:
    print(f"- {chunk.metadata.get('section')}: {chunk.content[:50]}...")
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ìƒì„±ëœ ì²­í¬ ìˆ˜: 175
- ì„œë¹„ìŠ¤ì•ˆë‚´: ì§ˆë¬¸: ì´ìš© ì‹œê°„ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? ë‹µë³€: í‰ì¼ 09:00~18:00ì…ë‹ˆë‹¤...
- ìš”ê¸ˆì•ˆë‚´: ì§ˆë¬¸: ì´ìš© ìš”ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”? ë‹µë³€: 1ì‹œê°„ ê¸°ì¤€ 10,000ì›ì…ë‹ˆë‹¤...
- ìœ„ì¹˜ì•ˆë‚´: ì§ˆë¬¸: ì£¼ì°¨ ê°€ëŠ¥í•œê°€ìš”? ë‹µë³€: ë„¤, ë¬´ë£Œ ì£¼ì°¨ ì§€ì›í•©ë‹ˆë‹¤...
```

### 2. ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì‚¬ìš©

```python
processor = DocumentProcessorFactory.create(
    'faq',
    content_template='Q: {question}\nA: {answer}'
)

chunks = processor.process('data/FAQ.xlsx')
```

### 3. ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©

```python
from app.modules.core.documents import (
    Document,
    Chunk,
    SimpleChunker,
    RuleBasedExtractor,
    FAQProcessor
)

# ì»¤ìŠ¤í…€ ì „ëµ ì¡°í•©
chunker = SimpleChunker(content_template='ì§ˆë¬¸: {question}\në‹µë³€: {answer}')
extractor = RuleBasedExtractor(use_konlpy=True)

# í”„ë¡œì„¸ì„œ ìƒì„±
processor = FAQProcessor(
    chunker=chunker,
    metadata_extractor=extractor
)

# ì²˜ë¦¬
chunks = processor.process('data/FAQ.xlsx')
```

## ğŸ“Š ë°ì´í„° ëª¨ë¸

### Document

ì›ë³¸ ë¬¸ì„œë¥¼ í‘œí˜„í•˜ëŠ” ë°ì´í„° ëª¨ë¸:

```python
from app.modules.core.documents import Document

doc = Document(
    source='data/faq.xlsx',
    doc_type='FAQ',
    data=[{'ì§ˆë¬¸': '...', 'ë‹µë³€': '...'}],
    metadata={'category': 'general'}
)

print(doc.total_items)      # 175
print(doc.is_structured)    # True
```

### Chunk

ë¶„í• ëœ ë¬¸ì„œ ì¡°ê°ì„ í‘œí˜„í•˜ëŠ” ë°ì´í„° ëª¨ë¸:

```python
from app.modules.core.documents import Chunk

chunk = Chunk(
    content='ì§ˆë¬¸: ... ë‹µë³€: ...',
    metadata={'section': 'ì„œë¹„ìŠ¤'},
    chunk_index=0
)

print(chunk.char_count)     # ë¬¸ì ìˆ˜
print(chunk.word_count)     # ë‹¨ì–´ ìˆ˜
print(chunk.has_embedding)  # False

# ì„ë² ë”© ì„¤ì •
chunk.set_embedding([0.1, 0.2, ...])
```

## ğŸ”§ ì²­í‚¹ ì „ëµ

### SimpleChunker (MVP)

1:1 ë§¤í•‘ ì²­í‚¹ - FAQì— ìµœì í™”:

```python
from app.modules.core.documents.chunking import SimpleChunker

chunker = SimpleChunker(
    content_template='{question}\n{answer}'
)

chunks = chunker.chunk(document)
```

### Phase 2 ì˜ˆì •

- **SemanticChunker**: ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ (Guidebookìš©)
- **ConversationChunker**: ëŒ€í™” ì²­í‚¹ (Kakaotalkìš©)

## ğŸ·ï¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

### RuleBasedExtractor (MVP)

ê·œì¹™ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ:

```python
from app.modules.core.documents.metadata import RuleBasedExtractor

extractor = RuleBasedExtractor(use_konlpy=True)
metadata = extractor.extract(chunk)

print(metadata['keywords'])          # ['ì„œë¹„ìŠ¤', 'ì´ìš©', 'ì‹œê°„']
print(metadata['contains_price'])    # True
print(metadata['categories'])        # ['ì„œë¹„ìŠ¤', 'ì´ìš©']
```

**ì¶”ì¶œ í•­ëª©**:
- `contains_price`: ê°€ê²© ì •ë³´ í¬í•¨ ì—¬ë¶€
- `keywords`: í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì •ê·œì‹ + ë‹¨ì–´ ë¶„ë¦¬)
- `has_date`: ë‚ ì§œ ì •ë³´ í¬í•¨ ì—¬ë¶€
- `categories`: ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬
- `content_type`: ì½˜í…ì¸  ìœ í˜• ('question', 'info', etc.)

**ì£¼ì˜**: LLMì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ë¹„ìš© 0ì›)

## ğŸ’¾ MongoDB ë¬¸ì„œ êµ¬ì¡°

íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ìƒì„±ë˜ëŠ” MongoDB ë¬¸ì„œ ìŠ¤í‚¤ë§ˆ:

```javascript
{
  // ë²¡í„° ê²€ìƒ‰ìš© (3072ì°¨ì›)
  "embedding": [0.123, -0.456, ...],

  // ì „ë¬¸ ê²€ìƒ‰ìš© ë³¸ë¬¸
  "content": "ì§ˆë¬¸: ì„œë¹„ìŠ¤ ì´ìš© ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”? ë‹µë³€: ...",

  // ë©”íƒ€ë°ì´í„° (ì´ì¤‘ êµ¬ì¡°)
  "metadata": {
    "metadata": {
      "section": "ì„œë¹„ìŠ¤",              // FAQ ì„¹ì…˜
      "doc_type": "FAQ",                 // ë¬¸ì„œ ìœ í˜•
      "source": "data/FAQ.xlsx",         // ì›ë³¸ íŒŒì¼
      "original_index": 0,               // FAQ íŒŒì¼ ë‚´ ìˆœì„œ (0ë¶€í„°)
      "question": "ì„œë¹„ìŠ¤ ì´ìš© ì‹œê°„ì€..."     // ì„ íƒì 
    }
  },

  // RuleBasedExtractor ì¶œë ¥ (LLM ë¯¸ì‚¬ìš©)
  "llm_enrichment": {
    "keywords": ["ì„œë¹„ìŠ¤", "ì´ìš©", "ì‹œê°„"]
  },

  // ê²€ìƒ‰ ìµœì í™” í•„ë“œ (ì„ íƒì )
  "contains_price": true,
  "categories": ["ì„œë¹„ìŠ¤", "ì´ìš©"],
  "content_type": "question"
}
```

**í•µì‹¬ í•„ë“œ**:
- `embedding`: ë²¡í„° ê²€ìƒ‰ ($vectorSearch)
- `content`: ì „ë¬¸ ê²€ìƒ‰ (Full-Text Search)
- `metadata.metadata`: í•„í„°ë§ìš©
- `llm_enrichment.keywords`: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë³´ì¡°
- `original_index`: FAQ íŒŒì¼ì—ì„œì˜ ì›ë˜ ìˆœì„œ (ì¶”ì ìš©)

### Phase 2 ì˜ˆì •

- **LLMBasedExtractor**: LLM ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

## ğŸ­ íŒ©í† ë¦¬ íŒ¨í„´

### ê¸°ë³¸ ì‚¬ìš©

```python
from app.modules.core.documents import DocumentProcessorFactory

# ì§€ì› íƒ€ì… í™•ì¸
print(DocumentProcessorFactory.get_supported_types())
# ['faq']

# í”„ë¡œì„¸ì„œ ìƒì„±
processor = DocumentProcessorFactory.create('faq')
```

### ì»¤ìŠ¤í…€ í”„ë¡œì„¸ì„œ ë“±ë¡

```python
from app.modules.core.documents import (
    BaseDocumentProcessor,
    DocumentProcessorFactory
)

class MyProcessor(BaseDocumentProcessor):
    def load(self, source):
        # ì»¤ìŠ¤í…€ ë¡œë”© ë¡œì§
        return Document(...)

# ë“±ë¡
DocumentProcessorFactory.register('custom', MyProcessor)

# ì‚¬ìš©
processor = DocumentProcessorFactory.create('custom')
```

## ğŸ“ íŒŒì¼ í˜•ì‹ ìš”êµ¬ì‚¬í•­

### FAQ (.xlsx, .xls, .csv)

í•„ìˆ˜ ì»¬ëŸ¼:
- `ì§ˆë¬¸` ë˜ëŠ” `question` (Q, queryë„ ê°€ëŠ¥)
- `ë‹µë³€` ë˜ëŠ” `answer` (A, responseë„ ê°€ëŠ¥)

ì„ íƒ ì»¬ëŸ¼:
- `ì„¹ì…˜ëª…` ë˜ëŠ” `section`
- `ì¹´í…Œê³ ë¦¬` ë˜ëŠ” `category`

ì˜ˆì‹œ:

| ì„¹ì…˜ëª… | ì§ˆë¬¸ | ë‹µë³€ |
|--------|------|------|
| ì„œë¹„ìŠ¤ | ì´ìš© ì‹œê°„ì€? | 09:00~18:00 |
| ìš”ê¸ˆ | ê°€ê²©ëŒ€ëŠ”? | 10,000ì›~ |

## ğŸ”„ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
from app.modules.core.documents import DocumentProcessorFactory

# 1. í”„ë¡œì„¸ì„œ ìƒì„±
processor = DocumentProcessorFactory.create('faq')

# 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
chunks = processor.process('data/FAQ.xlsx')
# ë‚´ë¶€ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë‹¨ê³„:
# - load(): íŒŒì¼ ë¡œë“œ â†’ Document ìƒì„±
# - validate(): ë¬¸ì„œ ê²€ì¦
# - chunk(): ì²­í‚¹ â†’ Chunk ë¦¬ìŠ¤íŠ¸ ìƒì„±
# - extract_metadata(): ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

# 3. ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ê³¼ ì—°ê²° (ì„ë² ë”© ìƒì„±)
from app.modules.core.embedding import GeminiEmbeddings

embedder = GeminiEmbeddings(...)
for chunk in chunks:
    embedding = embedder.embed_query(chunk.content)
    chunk.set_embedding(embedding)

# 4. ë²¡í„° DB ì €ì¥
from app.database import vector_store

for chunk in chunks:
    vector_store.save({
        'content': chunk.content,
        'embedding': chunk.embedding,
        'metadata': chunk.metadata
    })
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

ê°„ë‹¨í•œ í†µí•© í…ŒìŠ¤íŠ¸:

```python
# tests/integration/test_faq_processor.py
from app.modules.core.documents import DocumentProcessorFactory

def test_faq_processing():
    processor = DocumentProcessorFactory.create('faq')
    chunks = processor.process('tests/fixtures/sample_faq.xlsx')

    assert len(chunks) > 0
    assert chunks[0].content is not None
    assert 'section' in chunks[0].metadata
    assert 'keywords' in chunks[0].metadata
```

## ğŸ“ˆ Phase 2 í™•ì¥ ê³„íš

### Guidebook Processor
```python
processor = DocumentProcessorFactory.create('guidebook')
chunks = processor.process('data/guidebook.pdf')
```

### Kakaotalk Processor (ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹)
```python
processor = DocumentProcessorFactory.create('kakaotalk')
chunks = processor.process('data/conversation.txt')
```

## ğŸ”— ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©

### Low-level (ê¸°ì¡´)
```python
from app.modules.core.documents import DocumentProcessor

# ê¸°ì¡´ ë°©ì‹ (íŒŒì¼ ë¡œë”© + ì²­í‚¹ + ì„ë² ë”©)
processor = DocumentProcessor(config)
embedded_chunks = await processor.process_document_full('file.pdf')
```

### High-level (MVP Phase)
```python
from app.modules.core.documents import DocumentProcessorFactory

# ìƒˆë¡œìš´ ë°©ì‹ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ íŠ¹í™”)
processor = DocumentProcessorFactory.create('faq')
chunks = processor.process('data/FAQ.xlsx')
```

**ë‘ ì‹œìŠ¤í…œì€ ë…ë¦½ì ì´ë©° ë³‘í–‰ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.**

## ğŸ“š ì¶”ê°€ ìë£Œ

- [processingDocument.md](../../../../processingDocument.md) - RAG ë¬¸ì„œ ì²˜ë¦¬ ì „ëµ ê°€ì´ë“œ
- [CLAUDE.md](../../../../CLAUDE.md) - í”„ë¡œì íŠ¸ ê°œë°œ ê°€ì´ë“œë¼ì¸

## ğŸ¤ ê¸°ì—¬

ìƒˆë¡œìš´ ë¬¸ì„œ ìœ í˜• í”„ë¡œì„¸ì„œë¥¼ ì¶”ê°€í•˜ë ¤ë©´:

1. `BaseDocumentProcessor`ë¥¼ ìƒì†í•˜ëŠ” í´ë˜ìŠ¤ ì‘ì„±
2. `load()` ë©”ì„œë“œ êµ¬í˜„
3. `processors/` ë””ë ‰í† ë¦¬ì— íŒŒì¼ ìƒì„±
4. `DocumentProcessorFactory`ì— ë“±ë¡

**ì˜ˆì‹œ**: `processors/guidebook_processor.py` (Phase 2)
