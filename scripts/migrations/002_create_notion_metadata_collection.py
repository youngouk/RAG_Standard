#!/usr/bin/env python3
"""
Weaviate NotionMetadata ì»¬ë ‰ì…˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

Notion APIì—ì„œ ì¶”ì¶œí•œ êµ¬ì¡°í™” ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•  ë³„ë„ ì»¬ë ‰ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
ê¸°ì¡´ Documents ì»¬ë ‰ì…˜ê³¼ ë¶„ë¦¬í•˜ì—¬ ë°ì´í„° ê´€ë¦¬ë¥¼ ê²©ë¦¬í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/migrations/002_create_notion_metadata_collection.py
    python scripts/migrations/002_create_notion_metadata_collection.py --dry-run
    python scripts/migrations/002_create_notion_metadata_collection.py --delete-existing

ì‘ì„±ì¼: 2025-12-03
"""

import argparse
import json
import os
import sys
from pathlib import Path

import httpx

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from app.lib.logger import get_logger

logger = get_logger(__name__)

# =============================================================================
# ì„¤ì •
# =============================================================================

WEAVIATE_URL = os.getenv("WEAVIATE_URL", "https://weaviate-production-70aa.up.railway.app")

# NotionMetadata ì»¬ë ‰ì…˜ ìŠ¤í‚¤ë§ˆ
# Documents ì»¬ë ‰ì…˜ê³¼ ë™ì¼í•˜ê²Œ vectorizer: none ì‚¬ìš©
# (ë²¡í„°ëŠ” ì—…ë¡œë“œ ì‹œ ì§ì ‘ ì œê³µ)
NOTION_METADATA_SCHEMA = {
    "class": "NotionMetadata",
    "description": "Notion APIì—ì„œ ì¶”ì¶œí•œ êµ¬ì¡°í™” ë©”íƒ€ë°ì´í„° (ë²¡í„° ê²€ìƒ‰ìš©)",
    "vectorizer": "none",
    "properties": [
        # ì²­í¬ ì½˜í…ì¸  (ë²¡í„°í™” ëŒ€ìƒ)
        {"name": "content", "dataType": ["text"], "description": "ì²­í¬ í…ìŠ¤íŠ¸ ë‚´ìš©"},
        # ì—”í‹°í‹° ì‹ë³„
        {
            "name": "entity_id",
            "dataType": ["text"],
            "description": "Notion í˜ì´ì§€ UUID",
            "indexFilterable": True,
            "indexSearchable": False,
        },
        {
            "name": "entity_name",
            "dataType": ["text"],
            "description": "ì—”í‹°í‹°ëª…",
            "indexFilterable": True,
            "indexSearchable": True,
        },
        # ì¹´í…Œê³ ë¦¬
        {
            "name": "category",
            "dataType": ["text"],
            "description": "ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: domain_1 | domain_2)",
            "indexFilterable": True,
            "indexSearchable": False,
        },
        {
            "name": "source_file",
            "dataType": ["text"],
            "description": "notion_domain_1 | notion_domain_2",
            "indexFilterable": True,
            "indexSearchable": False,
        },
        # ì„¹ì…˜ ë¶„ë¥˜
        {
            "name": "section",
            "dataType": ["text"],
            "description": "ê·œì • | ë¹„ìš© | ìœ„ì¹˜ | ê¸°íƒ€",
            "indexFilterable": True,
            "indexSearchable": False,
        },
        # ì²­í‚¹ ë©”íƒ€
        {"name": "chunk_index", "dataType": ["int"], "description": "ì²­í¬ ì¸ë±ìŠ¤"},
        {"name": "total_chunks", "dataType": ["int"], "description": "í•´ë‹¹ ì—…ì²´ ì´ ì²­í¬ ìˆ˜"},
        {
            "name": "source_field",
            "dataType": ["text"],
            "description": "ì›ë³¸ Notion Property ì´ë¦„",
            "indexFilterable": True,
            "indexSearchable": False,
        },
        {"name": "token_estimate", "dataType": ["int"], "description": "ì¶”ì • í† í° ìˆ˜"},
        # ë™ê¸°í™” ë©”íƒ€
        {"name": "synced_at", "dataType": ["date"], "description": "ë™ê¸°í™” ì‹œê°„ (UTC)"},
        {
            "name": "notion_last_edited",
            "dataType": ["date"],
            "description": "Notion í˜ì´ì§€ ìµœì¢… ìˆ˜ì • ì‹œê°„",
        },
    ],
}


# =============================================================================
# í•¨ìˆ˜
# =============================================================================


def check_collection_exists(url: str, class_name: str) -> bool:
    """ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        response = httpx.get(f"{url}/v1/schema/{class_name}", timeout=30.0)
        return response.status_code == 200
    except Exception as e:
        logger.error(f"ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False


def delete_collection(url: str, class_name: str) -> bool:
    """ì»¬ë ‰ì…˜ ì‚­ì œ"""
    try:
        response = httpx.delete(f"{url}/v1/schema/{class_name}", timeout=30.0)
        if response.status_code in (200, 204):
            logger.info(f"âœ… ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ: {class_name}")
            return True
        else:
            logger.error(f"ì‚­ì œ ì‹¤íŒ¨ (status={response.status_code}): {response.text}")
            return False
    except Exception as e:
        logger.error(f"ì‚­ì œ ì˜¤ë¥˜: {e}")
        return False


def create_collection(url: str, schema: dict, dry_run: bool = False) -> bool:
    """ì»¬ë ‰ì…˜ ìƒì„±"""
    class_name = schema["class"]

    if dry_run:
        logger.info(f"[DRY-RUN] ì»¬ë ‰ì…˜ ìƒì„± ì˜ˆì •: {class_name}")
        logger.info(f"ìŠ¤í‚¤ë§ˆ:\n{json.dumps(schema, indent=2, ensure_ascii=False)}")
        return True

    try:
        response = httpx.post(f"{url}/v1/schema", json=schema, timeout=60.0)

        if response.status_code == 200:
            logger.info(f"âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {class_name}")
            return True
        else:
            logger.error(f"ìƒì„± ì‹¤íŒ¨ (status={response.status_code}): {response.text}")
            return False

    except Exception as e:
        logger.error(f"ìƒì„± ì˜¤ë¥˜: {e}")
        return False


def get_collection_info(url: str, class_name: str) -> dict | None:
    """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
    try:
        response = httpx.get(f"{url}/v1/schema/{class_name}", timeout=30.0)
        if response.status_code == 200:
            return response.json()
        return None
    except Exception:
        return None


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    parser = argparse.ArgumentParser(description="Weaviate NotionMetadata ì»¬ë ‰ì…˜ ìƒì„±")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ìƒì„± ì—†ì´ ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥")
    parser.add_argument(
        "--delete-existing", action="store_true", help="ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œ í›„ ì¬ìƒì„±"
    )
    parser.add_argument("--url", type=str, default=WEAVIATE_URL, help="Weaviate URL")

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸš€ Weaviate NotionMetadata ì»¬ë ‰ì…˜ ìƒì„±")
    print("=" * 60)
    print(f"URL: {args.url}")
    print(f"ì»¬ë ‰ì…˜: {NOTION_METADATA_SCHEMA['class']}")
    print(f"Properties: {len(NOTION_METADATA_SCHEMA['properties'])}ê°œ")
    print()

    # 1. ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
    class_name = NOTION_METADATA_SCHEMA["class"]
    exists = check_collection_exists(args.url, class_name)

    if exists:
        logger.info(f"âš ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ë°œê²¬: {class_name}")

        if args.delete_existing:
            logger.info("ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì¤‘...")
            if not delete_collection(args.url, class_name):
                logger.error("ì‚­ì œ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
        else:
            # ê¸°ì¡´ ì •ë³´ ì¶œë ¥
            info = get_collection_info(args.url, class_name)
            if info:
                prop_count = len(info.get("properties", []))
                logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ ì •ë³´: {prop_count}ê°œ properties")

            logger.info("ê¸°ì¡´ ì»¬ë ‰ì…˜ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‚­ì œí•˜ë ¤ë©´ --delete-existing ì‚¬ìš©")
            return

    # 2. ì»¬ë ‰ì…˜ ìƒì„±
    if create_collection(args.url, NOTION_METADATA_SCHEMA, dry_run=args.dry_run):
        if not args.dry_run:
            # 3. ìƒì„± í™•ì¸
            info = get_collection_info(args.url, class_name)
            if info:
                print()
                print("=" * 60)
                print("âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
                print("=" * 60)
                print(f"Class: {info.get('class')}")
                print(f"Vectorizer: {info.get('vectorizer')}")
                print(f"Properties: {len(info.get('properties', []))}ê°œ")

                print("\nProperty ëª©ë¡:")
                for prop in info.get("properties", []):
                    print(f"  - {prop['name']}: {prop['dataType']}")


if __name__ == "__main__":
    main()
